{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c65a39d8-45ca-4022-8c04-3f344ad13472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80bf62d2-0ff1-4ec2-bd55-ff99f4592701",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d743cad-d204-4061-acbe-b004f29969b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ec734-da18-477b-bce2-2381864ad919",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbbda346-2f1a-4e1d-8c16-e4ebe369816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el tamaño del dataset\n",
    "n_dataset = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21293518-fca1-4271-a1b0-adc1654045d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date\n",
    "date_list=[datetime.today()- relativedelta(months = x) for x in range(50,-1,-1)]\n",
    "month_list=[datetime.strftime(x,'%Y%m') for x in date_list]\n",
    "\n",
    "n = len(month_list)\n",
    "array = np.random.choice(range(5,10,1), size=n)\n",
    "array = array/sum(array)\n",
    "date_data = np.random.choice(month_list, size=n_dataset, p=array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4cd09b1-c91d-465a-8c12-e97013db321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client_id\n",
    "unique_client_id = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "client_id_data = np.random.choice(unique_client_id, size=n_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7389bba5-6a15-47dd-a17f-3b258b21ebcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>client_id</th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202112</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201910</td>\n",
       "      <td>u</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202006</td>\n",
       "      <td>x</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date client_id  Y  X1  X2  X3\n",
       "0  202112         n  0   5  44  -9\n",
       "1  201910         u  0   4  29   9\n",
       "2  202006         x  0   7  42   6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'date': date_data,\n",
    "                   'client_id': client_id_data,\n",
    "                   'Y': np.random.choice([1,0], size=n_dataset, p=[0.05,0.95]), # If purchased the product or not\n",
    "                   'X1': np.random.choice(range(10), size=n_dataset),\n",
    "                   'X2': np.random.choice(range(100), size=n_dataset),\n",
    "                   'X3': np.random.choice(range(-10,10,1), size=n_dataset)\n",
    "})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e3cd1-9a73-4f59-9b2b-de00b7c3a8d8",
   "metadata": {},
   "source": [
    "# Para utilizar estos custom-time-series-split:\n",
    "\n",
    "- Los datos deben estar preprocesados y listos para el entrenamiento (considerar NaNs)\n",
    "- La data debe tener una fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48445e7b-9a31-4891-aae5-eb3defcfbcdb",
   "metadata": {},
   "source": [
    "### Custom time-series split: Ventana móvil con tamaño FIJO\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "`TRAIN:  ['201801', '201802', '201803'] TEST:  ['201804']` <br>\n",
    "`TRAIN:  ['201802', '201803', '201804'] TEST:  ['201805']` <br>\n",
    "`TRAIN:  ['201803', '201804', '201805'] TEST:  ['201806']` <br>\n",
    "`TRAIN:  ['201804', '201805', '201806'] TEST:  ['201807']` <br>\n",
    "`TRAIN:  ['201805', '201806', '201807'] TEST:  ['201808']` <br>\n",
    "`TRAIN:  ['201806', '201807', '201808'] TEST:  ['201809']` <br>\n",
    "`TRAIN:  ['201807', '201808', '201809'] TEST:  ['201810']` <br>\n",
    "`TRAIN:  ['201808', '201809', '201810'] TEST:  ['201811']` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4aacede-a8a5-41bf-ac7b-ed21607b0150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  ['201801', '201802', '201803'] TEST:  ['201804']\n",
      "TRAIN:  ['201802', '201803', '201804'] TEST:  ['201805']\n",
      "TRAIN:  ['201803', '201804', '201805'] TEST:  ['201806']\n",
      "TRAIN:  ['201804', '201805', '201806'] TEST:  ['201807']\n",
      "TRAIN:  ['201805', '201806', '201807'] TEST:  ['201808']\n",
      "TRAIN:  ['201806', '201807', '201808'] TEST:  ['201809']\n",
      "TRAIN:  ['201807', '201808', '201809'] TEST:  ['201810']\n",
      "TRAIN:  ['201808', '201809', '201810'] TEST:  ['201811']\n",
      "TRAIN:  ['201809', '201810', '201811'] TEST:  ['201812']\n",
      "TRAIN:  ['201810', '201811', '201812'] TEST:  ['201901']\n",
      "TRAIN:  ['201811', '201812', '201901'] TEST:  ['201902']\n",
      "TRAIN:  ['201812', '201901', '201902'] TEST:  ['201903']\n",
      "TRAIN:  ['201901', '201902', '201903'] TEST:  ['201904']\n",
      "TRAIN:  ['201902', '201903', '201904'] TEST:  ['201905']\n",
      "TRAIN:  ['201903', '201904', '201905'] TEST:  ['201906']\n",
      "TRAIN:  ['201904', '201905', '201906'] TEST:  ['201907']\n",
      "TRAIN:  ['201905', '201906', '201907'] TEST:  ['201908']\n",
      "TRAIN:  ['201906', '201907', '201908'] TEST:  ['201909']\n",
      "TRAIN:  ['201907', '201908', '201909'] TEST:  ['201910']\n",
      "TRAIN:  ['201908', '201909', '201910'] TEST:  ['201911']\n",
      "TRAIN:  ['201909', '201910', '201911'] TEST:  ['201912']\n",
      "TRAIN:  ['201910', '201911', '201912'] TEST:  ['202001']\n",
      "TRAIN:  ['201911', '201912', '202001'] TEST:  ['202002']\n",
      "TRAIN:  ['201912', '202001', '202002'] TEST:  ['202003']\n",
      "TRAIN:  ['202001', '202002', '202003'] TEST:  ['202004']\n",
      "TRAIN:  ['202002', '202003', '202004'] TEST:  ['202005']\n",
      "TRAIN:  ['202003', '202004', '202005'] TEST:  ['202006']\n",
      "TRAIN:  ['202004', '202005', '202006'] TEST:  ['202007']\n",
      "TRAIN:  ['202005', '202006', '202007'] TEST:  ['202008']\n",
      "TRAIN:  ['202006', '202007', '202008'] TEST:  ['202009']\n",
      "TRAIN:  ['202007', '202008', '202009'] TEST:  ['202010']\n",
      "TRAIN:  ['202008', '202009', '202010'] TEST:  ['202011']\n",
      "TRAIN:  ['202009', '202010', '202011'] TEST:  ['202012']\n",
      "TRAIN:  ['202010', '202011', '202012'] TEST:  ['202101']\n",
      "TRAIN:  ['202011', '202012', '202101'] TEST:  ['202102']\n",
      "TRAIN:  ['202012', '202101', '202102'] TEST:  ['202103']\n",
      "TRAIN:  ['202101', '202102', '202103'] TEST:  ['202104']\n",
      "TRAIN:  ['202102', '202103', '202104'] TEST:  ['202105']\n",
      "TRAIN:  ['202103', '202104', '202105'] TEST:  ['202106']\n",
      "TRAIN:  ['202104', '202105', '202106'] TEST:  ['202107']\n",
      "TRAIN:  ['202105', '202106', '202107'] TEST:  ['202108']\n",
      "TRAIN:  ['202106', '202107', '202108'] TEST:  ['202109']\n",
      "TRAIN:  ['202107', '202108', '202109'] TEST:  ['202110']\n",
      "TRAIN:  ['202108', '202109', '202110'] TEST:  ['202111']\n",
      "TRAIN:  ['202109', '202110', '202111'] TEST:  ['202112']\n",
      "TRAIN:  ['202110', '202111', '202112'] TEST:  ['202201']\n",
      "TRAIN:  ['202111', '202112', '202201'] TEST:  ['202202']\n",
      "TRAIN:  ['202112', '202201', '202202'] TEST:  ['202203']\n"
     ]
    }
   ],
   "source": [
    "data = df.sort_values(\"date\").reset_index(drop=True).copy() # Toma los índices, importante resetearlos después de ordenarlos\n",
    "month_list = data[\"date\"].drop_duplicates().tolist() # ['2021-01-01',  '2021-02-01',  '2021-03-01', .. ]\n",
    "\n",
    "splits = {'train': [], 'test': []}\n",
    "n = 3 # Tamaño de la ventana móvil\n",
    "\n",
    "for idx, yr in enumerate(month_list[:-n]):\n",
    "    train_mth = month_list[idx:idx+n]\n",
    "    test_mth = [month_list[idx+n]]\n",
    "    print('TRAIN: ', train_mth, 'TEST: ',test_mth)\n",
    "    \n",
    "    splits['train'].append(data.loc[data.date.isin(train_mth), :])\n",
    "    splits['test'].append(data.loc[data.date.isin(test_mth), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d611714a-22e6-4677-99da-63375bfbd2cb",
   "metadata": {},
   "source": [
    "### Custom time-series split: Ventana móvil con tamaño VARIABLE hasta un threshold de tamaño\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "`TRAIN:  ['201801'] TEST:  ['201802']`<br>\n",
    "`TRAIN:  ['201801', '201802'] TEST:  ['201803']`<br>\n",
    "`TRAIN:  ['201801', '201802', '201803'] TEST:  ['201804']`<br>\n",
    "`TRAIN:  ['201801', '201802', '201803', '201804'] TEST:  ['201805']`<br>\n",
    "`TRAIN:  ['201802', '201803', '201804', '201805'] TEST:  ['201806']`<br>\n",
    "`TRAIN:  ['201803', '201804', '201805', '201806'] TEST:  ['201807']`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d9c9b45-8a9a-4bf0-9759-48de2734be89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:  ['201801'] TEST:  ['201802']\n",
      "TRAIN:  ['201801', '201802'] TEST:  ['201803']\n",
      "TRAIN:  ['201801', '201802', '201803'] TEST:  ['201804']\n",
      "TRAIN:  ['201801', '201802', '201803', '201804'] TEST:  ['201805']\n",
      "TRAIN:  ['201802', '201803', '201804', '201805'] TEST:  ['201806']\n",
      "TRAIN:  ['201803', '201804', '201805', '201806'] TEST:  ['201807']\n",
      "TRAIN:  ['201804', '201805', '201806', '201807'] TEST:  ['201808']\n",
      "TRAIN:  ['201805', '201806', '201807', '201808'] TEST:  ['201809']\n",
      "TRAIN:  ['201806', '201807', '201808', '201809'] TEST:  ['201810']\n",
      "TRAIN:  ['201807', '201808', '201809', '201810'] TEST:  ['201811']\n",
      "TRAIN:  ['201808', '201809', '201810', '201811'] TEST:  ['201812']\n",
      "TRAIN:  ['201809', '201810', '201811', '201812'] TEST:  ['201901']\n",
      "TRAIN:  ['201810', '201811', '201812', '201901'] TEST:  ['201902']\n",
      "TRAIN:  ['201811', '201812', '201901', '201902'] TEST:  ['201903']\n",
      "TRAIN:  ['201812', '201901', '201902', '201903'] TEST:  ['201904']\n",
      "TRAIN:  ['201901', '201902', '201903', '201904'] TEST:  ['201905']\n",
      "TRAIN:  ['201902', '201903', '201904', '201905'] TEST:  ['201906']\n",
      "TRAIN:  ['201903', '201904', '201905', '201906'] TEST:  ['201907']\n",
      "TRAIN:  ['201904', '201905', '201906', '201907'] TEST:  ['201908']\n",
      "TRAIN:  ['201905', '201906', '201907', '201908'] TEST:  ['201909']\n",
      "TRAIN:  ['201906', '201907', '201908', '201909'] TEST:  ['201910']\n",
      "TRAIN:  ['201907', '201908', '201909', '201910'] TEST:  ['201911']\n",
      "TRAIN:  ['201908', '201909', '201910', '201911'] TEST:  ['201912']\n",
      "TRAIN:  ['201909', '201910', '201911', '201912'] TEST:  ['202001']\n",
      "TRAIN:  ['201910', '201911', '201912', '202001'] TEST:  ['202002']\n",
      "TRAIN:  ['201911', '201912', '202001', '202002'] TEST:  ['202003']\n",
      "TRAIN:  ['201912', '202001', '202002', '202003'] TEST:  ['202004']\n",
      "TRAIN:  ['202001', '202002', '202003', '202004'] TEST:  ['202005']\n",
      "TRAIN:  ['202002', '202003', '202004', '202005'] TEST:  ['202006']\n",
      "TRAIN:  ['202003', '202004', '202005', '202006'] TEST:  ['202007']\n",
      "TRAIN:  ['202004', '202005', '202006', '202007'] TEST:  ['202008']\n",
      "TRAIN:  ['202005', '202006', '202007', '202008'] TEST:  ['202009']\n",
      "TRAIN:  ['202006', '202007', '202008', '202009'] TEST:  ['202010']\n",
      "TRAIN:  ['202007', '202008', '202009', '202010'] TEST:  ['202011']\n",
      "TRAIN:  ['202008', '202009', '202010', '202011'] TEST:  ['202012']\n",
      "TRAIN:  ['202009', '202010', '202011', '202012'] TEST:  ['202101']\n",
      "TRAIN:  ['202010', '202011', '202012', '202101'] TEST:  ['202102']\n",
      "TRAIN:  ['202011', '202012', '202101', '202102'] TEST:  ['202103']\n",
      "TRAIN:  ['202012', '202101', '202102', '202103'] TEST:  ['202104']\n",
      "TRAIN:  ['202101', '202102', '202103', '202104'] TEST:  ['202105']\n",
      "TRAIN:  ['202102', '202103', '202104', '202105'] TEST:  ['202106']\n",
      "TRAIN:  ['202103', '202104', '202105', '202106'] TEST:  ['202107']\n",
      "TRAIN:  ['202104', '202105', '202106', '202107'] TEST:  ['202108']\n",
      "TRAIN:  ['202105', '202106', '202107', '202108'] TEST:  ['202109']\n",
      "TRAIN:  ['202106', '202107', '202108', '202109'] TEST:  ['202110']\n",
      "TRAIN:  ['202107', '202108', '202109', '202110'] TEST:  ['202111']\n",
      "TRAIN:  ['202108', '202109', '202110', '202111'] TEST:  ['202112']\n",
      "TRAIN:  ['202109', '202110', '202111', '202112'] TEST:  ['202201']\n",
      "TRAIN:  ['202110', '202111', '202112', '202201'] TEST:  ['202202']\n",
      "TRAIN:  ['202111', '202112', '202201', '202202'] TEST:  ['202203']\n"
     ]
    }
   ],
   "source": [
    "data = df.sort_values(\"date\").reset_index(drop=True).copy() # Toma los índices, importante resetearlos después de ordenarlos\n",
    "month_list = data[\"date\"].drop_duplicates().tolist() # ['2021-01-01',  '2021-02-01',  '2021-03-01', .. ]\n",
    "\n",
    "splits = {'train': [], 'test': []}\n",
    "n = 1 # Tamaño inicial de la ventana móvil\n",
    "threshold = 4 # Tamaño de la ventana fija\n",
    "\n",
    "for idx, yr in enumerate(month_list[:-n]):\n",
    "    \n",
    "    if idx + n <= threshold:\n",
    "        train_mth = month_list[:idx+n]\n",
    "        test_mth = [month_list[idx+n]]\n",
    "        print('TRAIN: ', train_mth, 'TEST: ',test_mth)\n",
    "\n",
    "    else:\n",
    "        train_mth = month_list[idx-threshold+n:idx+n]\n",
    "        test_mth = [month_list[idx+n]]\n",
    "        #print(idx, n)\n",
    "        print('TRAIN: ', train_mth, 'TEST: ',test_mth)\n",
    "\n",
    "    splits['train'].append(data.loc[data.date.isin(train_mth), :])\n",
    "    splits['test'].append(data.loc[data.date.isin(test_mth), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4db24780-1b97-4861-85fc-9f9e78e8288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cv = []\n",
    "\n",
    "for FOLD_train,FOLD_test in zip(splits['train'],splits['test']):\n",
    "    custom_cv.append((np.array(FOLD_train.index.values.tolist()),np.array(FOLD_test.index.values.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7279df7-1151-4b23-98a0-21b359f01237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>client_id</th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201801</td>\n",
       "      <td>p</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201801</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201801</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date client_id  Y  X1  X2  X3\n",
       "0  201801         p  0   5  90   7\n",
       "1  201801         o  0   7  14   9\n",
       "2  201801         w  0   0  78  -7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para visualizar\n",
    "splits['train'][0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85a46da6-82fb-49dc-b463-6e8e5163feb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201801    2208\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para visualizar\n",
    "splits['train'][0]['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f76a251a-e223-42c2-92ee-e98915f14eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201802    2411\n",
       "201801    2208\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para visualizar\n",
    "splits['train'][1]['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73fad797-3bc6-4128-9b8b-a3e4e982602b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201802    2411\n",
       "201803    2250\n",
       "201801    2208\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para visualizar\n",
    "splits['train'][2]['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a652cba-6721-4367-ac87-e546a2eedb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 201801    2208\n",
      "Name: date, dtype: int64\n",
      "test: 201802    2411\n",
      "Name: date, dtype: int64\n",
      "\n",
      "train: 201802    2411\n",
      "201801    2208\n",
      "Name: date, dtype: int64\n",
      "test: 201803    2250\n",
      "Name: date, dtype: int64\n",
      "\n",
      "train: 201802    2411\n",
      "201803    2250\n",
      "201801    2208\n",
      "Name: date, dtype: int64\n",
      "test: 201804    2162\n",
      "Name: date, dtype: int64\n",
      "\n",
      "train: 201802    2411\n",
      "201803    2250\n",
      "201801    2208\n",
      "201804    2162\n",
      "Name: date, dtype: int64\n",
      "test: 201805    1404\n",
      "Name: date, dtype: int64\n",
      "\n",
      "train: 201802    2411\n",
      "201803    2250\n",
      "201804    2162\n",
      "201805    1404\n",
      "Name: date, dtype: int64\n",
      "test: 201806    1714\n",
      "Name: date, dtype: int64\n",
      "\n",
      "train: 201803    2250\n",
      "201804    2162\n",
      "201806    1714\n",
      "201805    1404\n",
      "Name: date, dtype: int64\n",
      "test: 201807    2458\n",
      "Name: date, dtype: int64\n",
      "\n",
      "train: 201807    2458\n",
      "201804    2162\n",
      "201806    1714\n",
      "201805    1404\n",
      "Name: date, dtype: int64\n",
      "test: 201808    1637\n",
      "Name: date, dtype: int64\n",
      "\n",
      "train: 201807    2458\n",
      "201806    1714\n",
      "201808    1637\n",
      "201805    1404\n",
      "Name: date, dtype: int64\n",
      "test: 201809    2511\n",
      "Name: date, dtype: int64\n",
      "\n",
      "train: 201809    2511\n",
      "201807    2458\n",
      "201806    1714\n",
      "201808    1637\n",
      "Name: date, dtype: int64\n",
      "test: 201810    1901\n",
      "Name: date, dtype: int64\n",
      "\n",
      "train: 201809    2511\n",
      "201807    2458\n",
      "201810    1901\n",
      "201808    1637\n",
      "Name: date, dtype: int64\n",
      "test: 201811    1951\n",
      "Name: date, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Para visualizar\n",
    "for i in range(10):\n",
    "    print('train:', splits['train'][i]['date'].value_counts())\n",
    "    print('test:', splits['test'][i]['date'].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "af0be78c-4e2a-47da-b7fc-4eb4b2a01f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = data.drop(['date', 'client_id', 'Y'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "fc840232-b854-43dd-9c2c-bd6f1db07ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:  Gradient Boosting Classifier\n",
      "Fitting 50 folds for each of 1 candidates, totalling 50 fits\n",
      "0.9508799863444023 {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "training:  Random Forest\n",
      "Fitting 50 folds for each of 2 candidates, totalling 100 fits\n",
      "0.9509445931410814 {'max_depth': 3, 'min_samples_leaf': 5, 'n_estimators': 100}\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.1s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.8s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.8s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.4s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.1s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.8s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.5s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.8s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.1s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.7s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.9s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.4s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.1s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.7s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.5s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.9s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   1.4s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.1s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.7s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.9s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.7s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.3s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.1s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.4s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.8s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.5s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.8s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.1s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.1s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.9s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   3.2s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.6s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.7s\n",
      "[CV] END ...............learning_rate=0.01, n_estimators=500; total time=   2.8s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END ..max_depth=4, min_samples_leaf=5, n_estimators=100; total time=   0.5s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "dict_classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    #\"Linear SVM\": SVC(),\n",
    "    #\"XGB\": XGBRegressor(),\n",
    "    #\"Logistic Regression\": LogisticRegression(),\n",
    "    #\"Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    #\"Decision Tree\": DecisionTreeClassifier(),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"Random Forest\": {\"max_depth\": [3,4], \n",
    "                      \"min_samples_leaf\": [5],\n",
    "                      \"n_estimators\": [100]},\n",
    "\n",
    "    \"Gradient Boosting Classifier\": {\"learning_rate\": [0.01], \n",
    "                                     \"n_estimators\": [500],\n",
    "                                     },\n",
    "    \n",
    "    #\"Linear SVM\": {\"kernel\": [\"rbf\", \"poly\"], \"gamma\": [\"auto\", \"scale\"], \"degree\": range(1, 4, 1)},\n",
    "    #\"XGB\": {'min_child_weight': [1, 5, 10],\n",
    "    #        'gamma': [0.1, 1, 1.5, 2, 5],\n",
    "    #        'subsample': [0.6, 0.8, 1.0],\n",
    "    #        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    #        'max_depth': [3, 4, 5], \n",
    "    #        \"n_estimators\": [300, 600],\n",
    "    #        \"learning_rate\": [0.001, 0.01, 0.1],\n",
    "    #        },\n",
    "    #\"Logistic Regression\": {'penalty': ['none', 'l2'], \n",
    "    #                        'C': [1]},\n",
    "    #\"Nearest Neighbors\": {'n_neighbors': [3, 5, 11, 19], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']},\n",
    "    #\"Decision Tree\": {'criterion': ['gini', 'entropy'], 'max_depth': np.arange(3, 15)},\n",
    "}\n",
    "\n",
    "for classifier_name in dict_classifiers.keys() & params:\n",
    "\n",
    "    print(\"training: \", classifier_name)\n",
    "    gridSearch = GridSearchCV(\n",
    "        estimator=dict_classifiers[classifier_name], \n",
    "        param_grid=params[classifier_name], \n",
    "        cv=custom_cv, \n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    gridSearch.fit(data[X_cols].to_numpy(), # shoud have shape of (n_samples, n_features) \n",
    "                   data[['Y']].to_numpy().reshape((-1))) #this should be an array with shape (n_samples,)\n",
    "    print(gridSearch.best_score_, gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08ab84ef-773f-45c1-ab77-8d6bce2a05df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.metrics._scorer._passthrough_scorer(estimator, *args, **kwargs)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearch.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4acd1ece-9026-43d5-a38d-63175f88a7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, min_samples_leaf=5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747a1ae2-53b9-46eb-ba96-55144ce4129a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m89"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
